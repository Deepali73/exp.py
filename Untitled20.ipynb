{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e92e42-f1e8-49a6-9f4b-7c5cd6692b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from deepface import DeepFace\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import numpy as np\n",
    "import time\n",
    "import traceback\n",
    "import urllib.parse\n",
    "\n",
    "# ---------- Setup ----------\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)\n",
    "\n",
    "emotion_queries = {\n",
    "    \"happy\": \"hindi happy dance songs\",\n",
    "    \"sad\": \"hindi sad songs playlist\",\n",
    "    \"angry\": \"hindi angry pump up songs\"\n",
    "}\n",
    "\n",
    "track_order = list(emotion_queries.keys())\n",
    "track_index = 0\n",
    "last_emotion = \"\"\n",
    "last_side = \"\"\n",
    "last_play_time = 0\n",
    "current_driver = None  # To track Selenium browser instance\n",
    "\n",
    "# ---------- Webcam Setup ----------\n",
    "cap = cv2.VideoCapture(0)\n",
    "time.sleep(2)  # Allow webcam to initialize\n",
    "\n",
    "# ---------- Preload DeepFace Model ----------\n",
    "print(\"âš™ï¸ Loading DeepFace models...\")\n",
    "_ = DeepFace.analyze(\n",
    "    img_path=np.zeros((224, 224, 3), dtype=np.uint8),\n",
    "    actions=['emotion'],\n",
    "    enforce_detection=False,\n",
    "    detector_backend='mediapipe'\n",
    ")\n",
    "print(\"âœ… DeepFace models loaded.\")\n",
    "\n",
    "# ---------- Play YouTube Video via Selenium ----------\n",
    "def play_on_youtube(search_query):\n",
    "    global current_driver\n",
    "\n",
    "    # Close previous video if open\n",
    "    if current_driver:\n",
    "        try:\n",
    "            current_driver.quit()\n",
    "            print(\"ðŸ›‘ Closed previous video.\")\n",
    "        except Exception as e:\n",
    "            print(\"âš ï¸ Error closing previous browser:\", e)\n",
    "\n",
    "    try:\n",
    "        print(f\"ðŸ”Ž Searching YouTube for: {search_query}\")\n",
    "        query = urllib.parse.quote(search_query)\n",
    "        search_url = f\"https://www.youtube.com/results?search_query={query}\"\n",
    "\n",
    "        # Setup browser\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--start-maximized\")\n",
    "        options.add_argument(\"--disable-infobars\")\n",
    "        options.add_argument(\"--disable-extensions\")\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        driver.get(search_url)\n",
    "\n",
    "        # Wait and click first video\n",
    "        time.sleep(3)\n",
    "        first_video = driver.find_element(By.ID, \"video-title\")\n",
    "        first_video.click()\n",
    "        current_driver = driver\n",
    "        print(\"ðŸŽ¬ Playing video...\")\n",
    "\n",
    "    except Exception:\n",
    "        print(\"âŒ YouTube playback error:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "# ---------- Main Loop ----------\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    # ----- Emotion Detection -----\n",
    "    try:\n",
    "        emotion_result = DeepFace.analyze(\n",
    "            rgb,\n",
    "            actions=['emotion'],\n",
    "            enforce_detection=False,\n",
    "            detector_backend='mediapipe'\n",
    "        )\n",
    "        emotion = emotion_result[0]['dominant_emotion']\n",
    "        cv2.putText(frame, f\"Emotion: {emotion}\", (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        current_time = time.time()\n",
    "        if emotion in emotion_queries and emotion != last_emotion and (current_time - last_play_time) > 10:\n",
    "            play_on_youtube(emotion_queries[emotion])\n",
    "            last_emotion = emotion\n",
    "            track_index = track_order.index(emotion)\n",
    "            last_play_time = current_time\n",
    "\n",
    "    except Exception:\n",
    "        print(\"Emotion detection error:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    # ----- Gesture Detection (Left/Right) -----\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "        left_eye = landmarks[33]\n",
    "        right_eye = landmarks[263]\n",
    "        face_center_x = (left_eye.x + right_eye.x) / 2\n",
    "\n",
    "        if face_center_x < 0.35 and last_side != \"left\":\n",
    "            track_index = (track_index + 1) % len(track_order)\n",
    "            emotion = track_order[track_index]\n",
    "            play_on_youtube(emotion_queries[emotion])\n",
    "            last_emotion = emotion\n",
    "            last_play_time = time.time()\n",
    "            last_side = \"left\"\n",
    "\n",
    "        elif face_center_x > 0.65 and last_side != \"right\":\n",
    "            track_index = (track_index - 1) % len(track_order)\n",
    "            emotion = track_order[track_index]\n",
    "            play_on_youtube(emotion_queries[emotion])\n",
    "            last_emotion = emotion\n",
    "            last_play_time = time.time()\n",
    "            last_side = \"right\"\n",
    "\n",
    "        elif 0.35 <= face_center_x <= 0.65:\n",
    "            last_side = \"\"\n",
    "\n",
    "    # Display info\n",
    "    cv2.putText(frame, \"Language: Hindi\", (30, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Emotion YouTube Player - Hindi\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC to exit\n",
    "        break\n",
    "\n",
    "# ---------- Cleanup ----------\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if current_driver:\n",
    "    try:\n",
    "        current_driver.quit()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971443bd-f60c-4b9b-96c7-d7a80dd3ead8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
